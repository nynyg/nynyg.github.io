<!doctype html>
<html xmlns="http://www.w3.org/1999/xhtml" class="gr__yf_io">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Nan Yang</title>
    <script src="https://kit.fontawesome.com/6f1b7e4a7f.js" crossorigin="anonymous"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,400;1,100;1,400&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css"
        integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="./files/main.css">
</head>

<body data-gr-c-s-loaded="true" data-new-gr-c-s-check-loaded="14.1043.0" data-gr-ext-installed="">
    <div class="sidebar">
        <div align="center">
            <div style="width: 200px;">
                <img src="./files/MyPhoto-circle.png" style="width: 100%;">
                <div style="text-align: center">
                    <h3><span class="me">Nan Yang / 杨楠</span></h3>
                    <!-- <h4>PhD @ TUM</h4> -->
                    <h4>Reality Labs Research</h4>
                </div>
            </div>
        </div>
        <div align="center">
            <ul style="list-style-type:none;">
                <li><a href="mailto:yangn@in.tum.de" target="_blank"><i class="fas fa-fw fa-lg fa-envelope"></i></a>
                </li>
                <li><a href="https://scholar.google.com/citations?user=pUj2ffwAAAAJ&hl=en" target="_blank"><i
                            class="fas fa-fw fa-lg fa-graduation-cap"></i></a></li>
                <li><a href="https://github.com/nynyg" target="_blank"><i class="fab fa-fw fa-lg fa-github"></i></a>
                </li>
                <li><a href="https://www.linkedin.com/in/nan-yang-089aa8aa/" target="_blank"><i
                            class="fab fa-fw fa-lg fa-linkedin"></i></a></li>
                <li><a href="https://twitter.com/NanYang719" target="_blank"><i
                            class="fab fa-fw fa-lg fa-twitter"></i></a></li>
            </ul>
        </div>
    </div>
    <div class="content">
        <h1>Nan Yang / 杨楠</h1>
        <br>I'm a research scientist at <a href="https://about.facebook.com/realitylabs/" target="_blank">Reality Labs
            Research</a>, Meta. I pursued my PhD at Technical University of Munich (TUM), supervised by <a
            href="https://vision.in.tum.de/members/cremers" target="_blank">Prof. Daniel Cremers</a>. During my PhD, I
        was also a senior computer vision engineer at <a href="https://www.artisense.ai/" target="_blank">Artisense</a>,
        a startup co-founded by Prof. Cremers. Prior to my PhD, I obtained my Master’s degree at TUM and my Bachelor’s
        degree at <a href="https://www.bupt.edu.cn/" target="_blank">Beijing University of Posts and
            Telecommunications</a>.
        <br>
        <br>My research interest is to leverage the power of Deep Neural Networks to overcome the limitations in
        traditional 3D computer vision and visual SLAM, such as visual odometry, relocalization, and dense mapping.

        <h3>News</h3>
        <ul>
            <li>Mar 2023: <a href="https://fwmb.github.io/bts/" target="_blank">Behind the Scenes</a> accepted at CVPR
                2023.</li>
            <li>Mar 2022: I've joined <a href="https://about.facebook.com/realitylabs/" target="_blank">Reality Labs
                    Research</a> as a Research Scientist.</li>
            <li>Dec 2021: <a href="https://vision.in.tum.de/research/vslam/tandem" target="_blank">TANDEM</a> accepted
                at CoRL 2021 and won the <a href="https://3dv2021.surrey.ac.uk/prizes/" target="_blank">Best Demo
                    Award</a> at 3DV 2021!</li>
            <li>May 2021: Received Outstading Reviewer for CVPR 2021.</li>
            <li>May 2018: Started PhD at <a href="https://vision.in.tum.de/home" target="_blank">CVAI</a> of TUM
                supervised by <a href="https://vision.in.tum.de/home" target="_blank">Prof. Daniel Cremers</a>.</li>
            <li>Mar 2018: Joined <a href="https://www.artisense.ai/" target="_blank">Artisense</a> as a senior computer
                vision & AI engineer.</li>
        </ul>
        <div id="publications">
            <h3>Publications</h3>
            <table class="table pub">
                <tbody>
                    <tr>
                        <td width="200"><img src="./files/bts.png" width="150"></td>
                        <td>
                            <div class="author">F. Wimbauer, <span class="me">N. Yang</span>, C. Rupprecht, and D.
                                Cremers</div>
                            <div class="title">Behind the Scenes: Density Fields for Single View Reconstruction</div>
                            <div class="journal"><span class="journal-title">IEEE Conference on Computer Vision and
                                    Pattern Recognition (CVPR)</span>, <span class="journal-year">2023</span></div>
                            <div class="link"><a href="https://fwmb.github.io/bts/" target="_blank">Project</a> / <a
                                    href="https://arxiv.org/abs/2301.07668" target="_blank">Paper</a> / <a
                                    href="https://github.com/Brummi/BehindTheScenes" target="_blank">Code</a> / <a
                                    href="https://www.youtube.com/watch?v=0VGKPmomrR8" target="_blank">Video</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/inc.jpg" width="150"></td>
                        <td>
                            <div class="author">X. Zuo, <span class="me">N. Yang</span>, N. Merrill, , B. Xu, and S.
                                Leutenegger</div>
                            <div class="title">Incremental Dense Reconstruction from Monocular Video with Guided Sparse
                                Feature Volume Fusion</div>
                            <div class="journal"><span class="journal-title">IEEE Robotics and Automation Letters
                                    (RA-L)</span>, <span class="journal-year">2023</span></div>
                            <div class="link"><a href="https://arxiv.org/abs/2305.14918" target="_blank">Paper</a> / <a
                                    href="https://www.youtube.com/watch?v=bY6zffvbSGE" target="_blank">Video</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/tandem.png" width="150"></td>
                        <td>
                            <div class="author">L. Köstler*, <span class="me">N. Yang*</span>, N. Zeller, and D. Cremers
                                (*equal contribution)</div>
                            <div class="title">TANDEM: Tracking and Dense Mapping in Real-time using Deep Multi-view
                                Stereo</div>
                            <div class="journal"><span class="journal-title">Conference on Robot Learning (CoRL)</span>,
                                <span class="journal-year">2021</span>
                            </div>
                            <div class="journal"><b style="color: red;">Best Demo Award at 3DV 2021</b></div>
                            <div class="link"><a href="https://go.vision.in.tum.de/tandem" target="_blank">Project</a> /
                                <a href="https://arxiv.org/abs/2111.07418" target="_blank">Paper</a> / <a
                                    href="https://github.com/tum-vision/tandem" target="_blank">Code</a> / <a
                                    href="https://youtu.be/L4C8Q6Gvl1w" target="_blank">Video</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/monorec.png" width="150"></td>
                        <td>
                            <div class="author">F. Wimbauer*, <span class="me">N. Yang*</span>, N. Zeller, and D.
                                Cremers (*equal contribution)</div>
                            <div class="title">MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments
                                from a Single Moving Camera</div>
                            <div class="journal"><span class="journal-title">IEEE Conference on Computer Vision and
                                    Pattern Recognition (CVPR)</span>, <span class="journal-year">2021</span></div>
                            <div class="link"><a href="https://vision.in.tum.de/research/monorec"
                                    target="_blank">Project</a> / <a href="https://arxiv.org/abs/2011.11814"
                                    target="_blank">Paper</a> / <a href="https://github.com/Brummi/MonoRec"
                                    target="_blank">Code</a> / <a href="https://youtu.be/XimdlXUamo0"
                                    target="_blank">Video</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/lm.jpeg" width="150"></td>
                        <td>
                            <div class="author">L. von Stumberg, P. Wenzel, <span class="me">N. Yang</span>, and D.
                                Cremers</div>
                            <div class="title">LM-Reloc: Levenberg-Marquardt Based Direct Visual Relocalization</div>
                            <div class="journal"><span class="journal-title">International Conference on 3D Vision
                                    (3DV)</span>, <span class="journal-year">2020</span></div>
                            <div class="link"><a href="https://vision.in.tum.de/research/vslam/lm-reloc"
                                    target="_blank">Project</a> / <a href="https://arxiv.org/abs/2010.06323"
                                    target="_blank">Paper</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/4seasons.png" width="150"></td>
                        <td>
                            <div class="author">P. Wenzel, R. Wang, <span class="me">N. Yang</span>, Q. Khan, Q. Cheng,
                                L. von Stumberg, N. Zeller, and D. Cremers</div>
                            <div class="title">4Seasons: A Cross-Season Dataset for Multi-Weather SLAM in Autonomous
                                Driving</div>
                            <div class="journal"><span class="journal-title">German Conference on Pattern Recognition
                                    (GCPR)</span>, <span class="journal-year">2020</span></div>
                            <div class="link"><a href="https://www.4seasons-dataset.com/" target="_blank">Project</a> /
                                <a href="https://arxiv.org/abs/2009.06364" target="_blank">Paper</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/koestler2020learning.png" width="150"></td>
                        <td>
                            <div class="author">L. Köstler, <span class="me">N. Yang</span>, R. Wang, and D. Cremers
                            </div>
                            <div class="title">Learning Monocular 3D Vehicle Detection without 3D Bounding Box Labels
                            </div>
                            <div class="journal"><span class="journal-title">German Conference on Pattern Recognition
                                    (GCPR)</span>, <span class="journal-year">2020</span></div>
                            <div class="link"><a href="https://lukaskoestler.com/ldwl" target="_blank">Project</a> / <a
                                    href="https://arxiv.org/abs/2010.03506" target="_blank">Paper</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/d3vo.gif" width="150"></td>
                        <td>
                            <div class="author"><span class="me">N. Yang</span>, L. von Stumberg, R. Wang, and D.
                                Cremers</div>
                            <div class="title">D3VO: Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual
                                Odometry</div>
                            <div class="journal"><span class="journal-title">IEEE Conference on Computer Vision and
                                    Pattern Recognition (CVPR)</span>, <span class="journal-year">2020</span></div>
                            <div class="journal"><span style="color: red;">Oral Presentation</span></div>
                            <div class="link"><a href="https://vision.in.tum.de/research/vslam/d3vo"
                                    target="_blank">Project</a> / <a href="https://arxiv.org/abs/2003.01060"
                                    target="_blank">Paper</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/directshape.png" width="150"></td>
                        <td>
                            <div class="author">R. Wang, <span class="me">N. Yang</span>, J. Stückler, and D. Cremers
                            </div>
                            <div class="title">DirectShape: Photometric Alignment of Shape Priors for Visual Vehicle
                                Pose and Shape Estimation</div>
                            <div class="journal"><span class="journal-title">IEEE International Conference on Robotics
                                    and Automation (ICRA)</span>, <span class="journal-year">2020</span></div>
                            <div class="link"><a href="https://vision.in.tum.de/research/vslam/direct-shape"
                                    target="_blank">Project</a> / <a href="https://arxiv.org/abs/1904.10097"
                                    target="_blank">Paper</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/mfgan.png" width="150"></td>
                        <td>
                            <div class="author">E. Jung*, <span class="me">N. Yang*</span>, and D. Cremers (*equal
                                contribution)</div>
                            <div class="title">Multi-Frame GAN: Image Enhancement for Stereo Visual Odometry in Low
                                Light</div>
                            <div class="journal"><span class="journal-title">Conference on Robot Learning (CoRL)</span>,
                                <span class="journal-year">2019</span>
                            </div>
                            <div class="journal"><span style="color: red;">Full Oral Presentation</span></div>
                            <div class="link"><a href="https://arxiv.org/abs/1910.06632" target="_blank">Paper</a> / <a
                                    href="https://youtu.be/OdYkFuZv204" target="_blank">Video</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/dvso.png" width="150"></td>
                        <td>
                            <div class="author"><span class="me">N. Yang</span>, R. Wang, J. Stückler, and D. Cremers
                            </div>
                            <div class="title">Deep Virtual Stereo Odometry: Leveraging Deep Depth Prediction for
                                Monocular Direct Sparse Odometry</div>
                            <div class="journal"><span class="journal-title">European Conference on Computer Vision
                                    (ECCV)</span>, <span class="journal-year">2018</span></div>
                            <div class="journal"><span style="color: red;">Oral Presentation</span></div>
                            <div class="link"><a href="https://vision.in.tum.de/research/vslam/dvso"
                                    target="_blank">Project</a> / <a href="https://arxiv.org/abs/1807.02570"
                                    target="_blank">Paper</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td width="200"><img src="./files/challenge.png" width="150"></td>
                        <td>
                            <div class="author"><span class="me">N. Yang*</span>, R. Wang*, X. Gao, and D. Cremers
                                (*equal contribution)</div>
                            <div class="title">Challenges in Monocular Visual Odometry: Photometric Calibration, Motion
                                Bias and Rolling Shutter Effect</div>
                            <div class="journal"><span class="journal-title">IEEE Robotics and Automation Letters (RA-L)
                                    & Int. Conference on Intelligent Robots and Systems (IROS)</span>, <span
                                    class="journal-year">2018</span></div>
                            <div class="link"><a href="https://vision.in.tum.de/research/vslam/dvso"
                                    target="_blank">Project</a> / <a href="https://arxiv.org/abs/1807.02570"
                                    target="_blank">Paper</a>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td></td>
                        <td></td>
                    </tr>
                </tbody>
            </table>
        </div>
        <div id="services">
            <h3>Reviewer</h3>
            <ul>
                <li>Computer Vision: CVPR, ECCV, ICCV</li>
                <li>Machine Learning: ICLR, AAAI, NeurIPS, PR</li>
                <li>Robotics: ICRA, IROS, RA-L, AURO, ISPRS, T-RO</li>
                <li>Computer Graphics: SIGGRAPH</li>
            </ul>
        </div>
        <div id="services">
            <h3>Workshop Organizer</h3>
            <ul>
                <li>Map-based Localization for Autonomous Driving Workshop, <a
                        href="https://sites.google.com/view/mlad-iccv2021" target="_blank">ICCV 2021</a></li>
                <li>Map-based Localization for Autonomous Driving Workshop, <a
                        href="https://sites.google.com/view/mlad-eccv2020" target="_blank">ECCV 2020</a></li>
            </ul>
        </div>
        <!--             <div id="services2">
                <h3> Services</h3>
                <ul>
                <li> PC Member of AAAI Conference on Artificial Intelligence (AAAI) 2020</li>
            </div> -->
    </div>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://code.jquery.com/jquery-1.12.4.min.js"
        integrity="sha384-nvAa0+6Qg9clwYCGGPpDQLVpLNn0fRaROjHqs13t4Ggj3Ez50XnGQqc/r8MhnRDZ"
        crossorigin="anonymous"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"
        integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd"
        crossorigin="anonymous"></script>
</body>

</html>